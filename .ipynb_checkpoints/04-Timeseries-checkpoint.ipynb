{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e555eaf0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os \n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "import keras\n",
    "#from tensorflow.python.keras import backend as K\n",
    "from tensorflow.python.keras import regularizers\n",
    "from tensorflow.python.keras.models import Sequential, Model\n",
    "from tensorflow.python.keras.layers import Flatten, Dense, Dropout, Input, concatenate, Activation, Concatenate, LSTM, GRU\n",
    "from tensorflow.python.keras.layers import Input, Conv2D, MaxPooling2D, UpSampling2D, Conv1D, BatchNormalization, GRU, Convolution1D, LSTM\n",
    "from tensorflow.python.keras.layers import UpSampling1D, MaxPooling1D, GlobalMaxPooling1D, GlobalAveragePooling1D,MaxPool1D\n",
    "from tensorflow.python.keras.callbacks import EarlyStopping, ModelCheckpoint, History, ReduceLROnPlateau\n",
    "#from tensorflow.keras.utils import np_utils\n",
    "import tensorflow as tf\n",
    "\n",
    "from sklearn.utils import class_weight\n",
    "from sklearn.metrics import average_precision_score, roc_auc_score, accuracy_score, f1_score\n",
    "import gc "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "473637c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "timeseries_path = \"data/timeseries/\"\n",
    "\n",
    "x_train = pd.read_pickle(os.path.join(timeseries_path, \"x_train_lstm.p\"))\n",
    "x_dev = pd.read_pickle(os.path.join(timeseries_path, \"x_dev_lstm.p\"))\n",
    "x_test = pd.read_pickle(os.path.join(timeseries_path, \"x_test_lstm.p\"))\n",
    "\n",
    "y_train = pd.read_pickle(os.path.join(timeseries_path, \"y_train.p\"))\n",
    "y_dev = pd.read_pickle(os.path.join(timeseries_path, \"y_dev.p\"))\n",
    "y_test = pd.read_pickle(os.path.join(timeseries_path, \"y_test.p\"))\n",
    "\n",
    "ys = pd.read_pickle(os.path.join(timeseries_path, \"ys.p\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "750346a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reset Keras Session\n",
    "def reset_keras(model):\n",
    "\n",
    "    try:\n",
    "        del model # this is from global space - change this as you need\n",
    "    except:\n",
    "        pass\n",
    "\n",
    "    gc.collect() # if it's done something you should see a number being outputted\n",
    "\n",
    "def make_prediction_timeseries(model, test_data):\n",
    "    \n",
    "    probs = model.predict(test_data)\n",
    "    y_pred = [1 if i>=0.5 else 0 for i in probs]\n",
    "    return probs, y_pred\n",
    "\n",
    "def save_scores_timeseries(predictions, probs, ground_truth):\n",
    "    \n",
    "    auc = roc_auc_score(ground_truth, probs)\n",
    "    auprc = average_precision_score(ground_truth, probs)\n",
    "    acc   = accuracy_score(ground_truth, predictions)\n",
    "    F1    = f1_score(ground_truth, predictions)\n",
    "    \n",
    "    result_dict = {}    \n",
    "    result_dict['auc'] = auc\n",
    "    result_dict['auprc'] = auprc\n",
    "    result_dict['acc'] = acc\n",
    "    result_dict['F1'] = F1\n",
    "\n",
    "\n",
    "    print(\"AUC: \", auc, \"AUPRC: \", auprc, \"ACC: \", acc, \"F1: \",F1)\n",
    "    return result_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "897f00fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "def timeseries_model():\n",
    "    sequence_input = Input(shape=(24,104),  name = \"timeseries_input\")\n",
    "\n",
    "\n",
    "    x = GRU(128)(sequence_input)    \n",
    "    FC1 = Dense(512, activation='relu')(x)\n",
    "    FC2 = Dropout(0.3)(FC1)\n",
    "    FC3 = Dense(256, activation='relu')(FC2)\n",
    "    \n",
    "    logits_regularizer = tf.keras.regularizers.L2(l2=0.05)\n",
    "    \n",
    "    sigmoid_pred = Dense(1, activation='sigmoid',use_bias=True,\n",
    "                         kernel_initializer=tf.keras.initializers.glorot_normal(),\n",
    "                  kernel_regularizer=logits_regularizer\n",
    "                        )(FC3)\n",
    "\n",
    "    model_temp = Model(inputs=sequence_input, outputs=sigmoid_pred)\n",
    "\n",
    "\n",
    "    model_temp.compile(loss='binary_crossentropy', optimizer='adam', metrics=['acc'])\n",
    "    return model_temp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12f4b48c",
   "metadata": {},
   "outputs": [],
   "source": [
    "epoch_num = 100\n",
    "model_patience = 4\n",
    "monitor_criteria = 'val_loss'\n",
    "batch_size = 32\n",
    "iteration_number = 10\n",
    "\n",
    "target_problems = ['mort_hosp', 'mort_icu', 'los_3', 'los_7']\n",
    "\n",
    "\n",
    "save_scores = {0:[], 1:[], 2:[], 3:[], 4:[], 5:[], 6:[], 7:[], 8:[], 9:[],}\n",
    "\n",
    "for iteration in range(0, iteration_number):\n",
    "    np.random.seed(iteration)\n",
    "    tf.random.set_seed(iteration)\n",
    "    \n",
    "    temp_results = []\n",
    "    for each_problem in target_problems:\n",
    "        print (iteration, \": Problem type: \", each_problem)\n",
    "        print (\"__________________\")\n",
    "\n",
    "\n",
    "        early_stopping_monitor = EarlyStopping(monitor=monitor_criteria, patience=model_patience)\n",
    "        best_model_name = \"models/timeseries/128+hidden/timeseries_best_model_128\"+str(iteration)+\".hdf5\"\n",
    "        checkpoint = ModelCheckpoint(best_model_name, monitor='val_loss', verbose=1,\n",
    "            save_best_only=True, mode='min', period=1)\n",
    "\n",
    "        callbacks = [early_stopping_monitor, checkpoint]\n",
    "\n",
    "        \n",
    "        model = timeseries_model()\n",
    "        \n",
    "#         class_weights = class_weight.compute_class_weight('balanced',\n",
    "#                                                          np.unique(y_train[each_problem]),\n",
    "#                                                          y_train[each_problem])\n",
    "#         class_weight_dict = dict(enumerate(class_weights))\n",
    "        \n",
    "        if each_problem == \"mort_icu\":\n",
    "            class_weight_dict = {0: 1, 1: 5}\n",
    "        else: \n",
    "            class_weights = class_weight.compute_class_weight('balanced',\n",
    "                                                             np.unique(y_train[each_problem]),\n",
    "                                                             y_train[each_problem])        \n",
    "            class_weight_dict = dict(enumerate(class_weights))\n",
    "            \n",
    "        model.fit(x_train, y_train[each_problem], epochs=epoch_num, verbose=1, \n",
    "                  validation_data=(x_dev, y_dev[each_problem]), callbacks=callbacks, batch_size= batch_size,\n",
    "                 class_weight=class_weight_dict)\n",
    "        \n",
    "        model.load_weights(best_model_name)\n",
    "\n",
    "        probs, predictions = make_prediction_timeseries(model, x_test)\n",
    "        scores = save_scores_timeseries(predictions, probs, y_test[each_problem].values)\n",
    "                \n",
    "        temp = {each_problem: scores}\n",
    "        temp_results.append(temp)\n",
    "        \n",
    "        del model\n",
    "        tf.keras.backend.clear_session()\n",
    "    save_scores[iteration] = temp_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c82a4f4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compare_result(data, target, metric):\n",
    "    res = 0\n",
    "    res_list = []\n",
    "    if target == \"mort_hosp\":\n",
    "        ind = 0\n",
    "    elif target == \"mort_icu\":\n",
    "        ind = 1\n",
    "    elif target == \"los_3\":\n",
    "        ind = 2\n",
    "    elif target == \"los_7\":\n",
    "        ind = 3\n",
    "    \n",
    "    counter = 0\n",
    "    for i,info in data.items():\n",
    "        #print(info[0])\n",
    "        if counter == 5:\n",
    "            break\n",
    "        counter +=1\n",
    "        res_list.append(info[ind][target][metric])\n",
    "        res += info[ind][target][metric]\n",
    "    \n",
    "    #print(target, metric, res / 5, np.mean(res_list), np.std(res_list))\n",
    "    print(target, metric,np.mean(res_list), np.std(res_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98558b2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "target = \"mort_hosp\"\n",
    "compare_result(save_scores, target, \"auc\")\n",
    "compare_result(save_scores, target, \"auprc\")\n",
    "compare_result(save_scores, target, \"F1\")\n",
    "print(\"\")\n",
    "target = \"mort_icu\"\n",
    "compare_result(save_scores, target, \"auc\")\n",
    "compare_result(save_scores, target, \"auprc\")\n",
    "compare_result(save_scores, target, \"F1\")\n",
    "print(\"\")\n",
    "target = \"los_3\"\n",
    "compare_result(save_scores, target, \"auc\")\n",
    "compare_result(save_scores, target, \"auprc\")\n",
    "compare_result(save_scores, target, \"F1\")\n",
    "print(\"\")\n",
    "target = \"los_7\"\n",
    "compare_result(save_scores, target, \"auc\")\n",
    "compare_result(save_scores, target, \"auprc\")\n",
    "compare_result(save_scores, target, \"F1\")\n",
    "print(\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7777baa",
   "metadata": {},
   "outputs": [],
   "source": [
    "path = \"models/timeseries/\"\n",
    "pd.to_pickle(save_scores, os.path.join(path, \"timeseries_score.p\"))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
